{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 小数据集训练CNN-其他对照组（dropout/L1/L2等其他抑制过拟合技术）\n",
    "## 基准组实验条件\n",
    "### 数据集：小数据集\n",
    "### 训练集：1,000/类别\n",
    "### 验证集：500/类别\n",
    "### 测试集：500/类别\n",
    "### 是否使用数据增强：否/是\n",
    "### 训练轮数：30\n",
    "### 可参考教材pp111-115"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 对照组之一：仅使用dropout选项"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 按需建模，dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "#conv2D的filters从32增加到128\n",
    "my_network_dropout = models.Sequential()\n",
    "#32个filter\n",
    "my_network_dropout.add(layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (150,150,3)))\n",
    "my_network_dropout.add(layers.MaxPooling2D((2,2)))\n",
    "#64个filter\n",
    "my_network_dropout.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "my_network_dropout.add(layers.MaxPooling2D((2,2)))\n",
    "#128个filter\n",
    "my_network_dropout.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n",
    "my_network_dropout.add(layers.MaxPooling2D((2,2)))\n",
    "#128个filter\n",
    "my_network_dropout.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n",
    "my_network_dropout.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "my_network_dropout.add(layers.Flatten()) #将3D展平为1D\n",
    "#为防止过拟合，使用dropout\n",
    "my_network_dropout.add(layers.Dropout(0.5))\n",
    "my_network_dropout.add(layers.Dense(512, activation = 'relu'))\n",
    "my_network_dropout.add(layers.Dense(1,activation='sigmoid'))#最后输出二元分类概率\n",
    "\n",
    "\n",
    "from keras import optimizers\n",
    "my_network_dropout.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 67s 669ms/step - loss: 0.6924 - acc: 0.5180 - val_loss: 0.6818 - val_acc: 0.6140\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 68s 684ms/step - loss: 0.6766 - acc: 0.5730 - val_loss: 0.6723 - val_acc: 0.5670\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 66s 665ms/step - loss: 0.6571 - acc: 0.6165 - val_loss: 0.6401 - val_acc: 0.6390\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 67s 667ms/step - loss: 0.6341 - acc: 0.6395 - val_loss: 0.6413 - val_acc: 0.6310\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 0.6044 - acc: 0.6700 - val_loss: 0.6104 - val_acc: 0.6700\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 98s 983ms/step - loss: 0.5864 - acc: 0.6935 - val_loss: 0.5916 - val_acc: 0.6970\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 91s 905ms/step - loss: 0.5465 - acc: 0.7225 - val_loss: 0.5683 - val_acc: 0.7050\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 72s 721ms/step - loss: 0.5293 - acc: 0.7280 - val_loss: 0.6522 - val_acc: 0.6240\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 89s 894ms/step - loss: 0.5064 - acc: 0.7545 - val_loss: 0.5628 - val_acc: 0.7140\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 82s 821ms/step - loss: 0.4873 - acc: 0.7600 - val_loss: 0.5866 - val_acc: 0.7030\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 79s 788ms/step - loss: 0.4631 - acc: 0.7760 - val_loss: 0.5619 - val_acc: 0.7070\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 79s 791ms/step - loss: 0.4438 - acc: 0.7975 - val_loss: 0.5889 - val_acc: 0.7080\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 0.4265 - acc: 0.8060 - val_loss: 0.5488 - val_acc: 0.7290\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 94s 941ms/step - loss: 0.4137 - acc: 0.8180 - val_loss: 0.5536 - val_acc: 0.7300\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 100s 1s/step - loss: 0.3940 - acc: 0.8235 - val_loss: 0.6000 - val_acc: 0.7160\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 100s 997ms/step - loss: 0.3744 - acc: 0.8305 - val_loss: 0.5217 - val_acc: 0.7470\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 99s 987ms/step - loss: 0.3616 - acc: 0.8540 - val_loss: 0.5223 - val_acc: 0.7540\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.3490 - acc: 0.8460 - val_loss: 0.5632 - val_acc: 0.7380\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.3275 - acc: 0.8580 - val_loss: 0.5875 - val_acc: 0.7310\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 100s 996ms/step - loss: 0.3335 - acc: 0.8560 - val_loss: 0.5484 - val_acc: 0.7500\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 100s 1s/step - loss: 0.3157 - acc: 0.8620 - val_loss: 0.5346 - val_acc: 0.7500\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 100s 995ms/step - loss: 0.2915 - acc: 0.8755 - val_loss: 0.5292 - val_acc: 0.7490\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 100s 996ms/step - loss: 0.2768 - acc: 0.8835 - val_loss: 0.5497 - val_acc: 0.7650\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 99s 988ms/step - loss: 0.2696 - acc: 0.8805 - val_loss: 0.5712 - val_acc: 0.7490\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 99s 995ms/step - loss: 0.2694 - acc: 0.8900 - val_loss: 0.5262 - val_acc: 0.7710\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 100s 999ms/step - loss: 0.2409 - acc: 0.9060 - val_loss: 0.5792 - val_acc: 0.7580\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 99s 995ms/step - loss: 0.2328 - acc: 0.9050 - val_loss: 0.5655 - val_acc: 0.7610\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 98s 984ms/step - loss: 0.2279 - acc: 0.9040 - val_loss: 0.6019 - val_acc: 0.7460\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 98s 983ms/step - loss: 0.1994 - acc: 0.9205 - val_loss: 0.6430 - val_acc: 0.7440\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.2087 - acc: 0.9180 - val_loss: 0.6003 - val_acc: 0.7510\n"
     ]
    }
   ],
   "source": [
    "history_droupout = my_network_dropout.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs = 30,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 50)\n",
    "\n",
    "my_network_dropout.save('D:/2-AI读书学习笔记/0-python深度学习/0-model_repo/cats_and_dogs_small_my_network_with_dropout.h5')\n",
    "\n",
    "import pickle\n",
    "with open('D:/2-AI读书学习笔记/0-python深度学习/0-model_repo/ch5_2_network_cnn_dropout_trainHistoryDict.txt', 'wb') as file_pi:\n",
    "    pickle.dump(history_droupout.history, file_pi)#将训练历史数据保存到指定文件中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 评估dropout选项对模型在测试集分类准确率的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.749"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "\n",
    "classes = ['cats','dogs']\n",
    "files_name = []\n",
    "test_true_labels = []\n",
    "test_pred_labels = []\n",
    "test_pred_probs = []\n",
    "\n",
    "for c in classes:\n",
    "    test_class_dir = 'D:/2-AI读书学习笔记/99-dataset-lib/cat_dog/small_dataset_cat_dog/test/{}'.format(c)\n",
    "    for f in os.listdir(test_class_dir):\n",
    "        \n",
    "        files_name.append(f)\n",
    "        test_true_labels.append(f[0:3])\n",
    "        \n",
    "        img_path = os.path.join(test_class_dir, f)\n",
    "        img = image.load_img(img_path, target_size = (150, 150))\n",
    "        #模型预测\n",
    "        pred = my_network_dropout.predict(preprocess_img(img))\n",
    "        test_pred_probs.append(pred)\n",
    "        \n",
    "        pred_label = None\n",
    "        if pred[0] > 0.5:\n",
    "            pred_label = 'dog'\n",
    "        else:\n",
    "            pred_label = 'cat'\n",
    "        test_pred_labels.append(pred_label)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data={'file':files_name, 'true_label':test_true_labels,  'pred_label':test_pred_labels, 'pred_prob':test_pred_probs})\n",
    "\n",
    "\n",
    "        \n",
    "pred_correct_records = df[df['true_label'] == df['pred_label']].shape[0]\n",
    "correct_rate = float(pred_correct_records)/float(1000)\n",
    "correct_rate        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 对照组之二：仅使用L1范数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 按需建模，设置regularizers.l1(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "#conv2D的filters从32增加到128\n",
    "my_network_L1 = models.Sequential()\n",
    "#32个filter\n",
    "my_network_L1.add(layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (150,150,3)))\n",
    "my_network_L1.add(layers.MaxPooling2D((2,2)))\n",
    "#64个filter\n",
    "my_network_L1.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "my_network_L1.add(layers.MaxPooling2D((2,2)))\n",
    "#128个filter\n",
    "my_network_L1.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n",
    "my_network_L1.add(layers.MaxPooling2D((2,2)))\n",
    "#128个filter\n",
    "my_network_L1.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n",
    "my_network_L1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "my_network_L1.add(layers.Flatten()) #将3D展平为1D\n",
    "#为防止过拟合，使用dropout\n",
    "#my_network_L1.add(layers.Dropout(0.5))\n",
    "my_network_L1.add(layers.Dense(512, kernel_regularizer = regularizers.l1(0.001), activation = 'relu'))\n",
    "my_network_L1.add(layers.Dense(1,activation='sigmoid'))#最后输出二元分类概率\n",
    "\n",
    "\n",
    "from keras import optimizers\n",
    "my_network_L1.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 101s 1s/step - loss: 32.7300 - acc: 0.5090 - val_loss: 20.6112 - val_acc: 0.5000\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 100s 1s/step - loss: 12.3326 - acc: 0.5275 - val_loss: 5.6398 - val_acc: 0.5730\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 100s 995ms/step - loss: 2.5087 - acc: 0.5445 - val_loss: 0.9935 - val_acc: 0.5920\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 100s 1s/step - loss: 0.9218 - acc: 0.5505 - val_loss: 0.8914 - val_acc: 0.5200\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 100s 999ms/step - loss: 0.8742 - acc: 0.5580 - val_loss: 0.8545 - val_acc: 0.6010\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 100s 999ms/step - loss: 0.8605 - acc: 0.5660 - val_loss: 0.8498 - val_acc: 0.5990\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.8512 - acc: 0.5670 - val_loss: 0.8442 - val_acc: 0.5670\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 99s 988ms/step - loss: 0.8446 - acc: 0.5900 - val_loss: 0.8332 - val_acc: 0.5890\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 72s 718ms/step - loss: 0.8406 - acc: 0.5935 - val_loss: 0.8275 - val_acc: 0.6020\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 71s 708ms/step - loss: 0.8376 - acc: 0.5895 - val_loss: 0.8488 - val_acc: 0.5890\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 69s 695ms/step - loss: 0.8363 - acc: 0.5930 - val_loss: 0.8206 - val_acc: 0.6050\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 68s 680ms/step - loss: 0.8285 - acc: 0.6050 - val_loss: 0.8213 - val_acc: 0.6120\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 68s 679ms/step - loss: 0.8281 - acc: 0.6110 - val_loss: 0.8464 - val_acc: 0.5810\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 68s 681ms/step - loss: 0.8251 - acc: 0.6125 - val_loss: 0.8107 - val_acc: 0.6320\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 68s 679ms/step - loss: 0.8199 - acc: 0.6190 - val_loss: 0.8164 - val_acc: 0.6260\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 67s 673ms/step - loss: 0.8180 - acc: 0.6390 - val_loss: 0.8031 - val_acc: 0.6480\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 68s 681ms/step - loss: 0.8149 - acc: 0.6235 - val_loss: 0.8424 - val_acc: 0.5840\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 67s 674ms/step - loss: 0.8101 - acc: 0.6265 - val_loss: 0.8125 - val_acc: 0.6320\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 68s 681ms/step - loss: 0.8042 - acc: 0.6475 - val_loss: 0.7919 - val_acc: 0.6590\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 67s 668ms/step - loss: 0.8018 - acc: 0.6340 - val_loss: 0.7892 - val_acc: 0.6520\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 68s 680ms/step - loss: 0.7983 - acc: 0.6575 - val_loss: 0.8045 - val_acc: 0.6400\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 68s 677ms/step - loss: 0.7929 - acc: 0.6645 - val_loss: 0.7945 - val_acc: 0.6510\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 68s 677ms/step - loss: 0.7875 - acc: 0.6750 - val_loss: 0.7900 - val_acc: 0.6650\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 68s 680ms/step - loss: 0.7893 - acc: 0.6680 - val_loss: 0.7868 - val_acc: 0.6680\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 68s 677ms/step - loss: 0.7800 - acc: 0.6770 - val_loss: 0.7770 - val_acc: 0.6720\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 68s 681ms/step - loss: 0.7815 - acc: 0.6740 - val_loss: 0.7733 - val_acc: 0.6900\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 69s 688ms/step - loss: 0.7791 - acc: 0.6880 - val_loss: 0.7679 - val_acc: 0.6880\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 68s 681ms/step - loss: 0.7755 - acc: 0.6795 - val_loss: 0.7682 - val_acc: 0.6880\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 68s 679ms/step - loss: 0.7706 - acc: 0.6905 - val_loss: 0.7722 - val_acc: 0.6820\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 68s 680ms/step - loss: 0.7697 - acc: 0.6770 - val_loss: 0.7791 - val_acc: 0.6750\n"
     ]
    }
   ],
   "source": [
    "history_L1 = my_network_L1.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs = 30,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 50)\n",
    "\n",
    "my_network_L1.save('D:/2-AI读书学习笔记/0-python深度学习/0-model_repo/cats_and_dogs_small_my_network_with_L1.h5')\n",
    "import pickle\n",
    "with open('D:/2-AI读书学习笔记/0-python深度学习/0-model_repo/ch5_2_network_cnn_L1_trainHistoryDict.txt', 'wb') as file_pi:\n",
    "    pickle.dump(history_L1.history, file_pi)#将训练历史数据保存到指定文件中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 评估L1选项对模型在测试集分类准确率的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.674"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "\n",
    "classes = ['cats','dogs']\n",
    "files_name = []\n",
    "test_true_labels = []\n",
    "test_pred_labels = []\n",
    "test_pred_probs = []\n",
    "\n",
    "for c in classes:\n",
    "    test_class_dir = 'D:/2-AI读书学习笔记/99-dataset-lib/cat_dog/small_dataset_cat_dog/test/{}'.format(c)\n",
    "    for f in os.listdir(test_class_dir):\n",
    "        \n",
    "        files_name.append(f)\n",
    "        test_true_labels.append(f[0:3])\n",
    "        \n",
    "        img_path = os.path.join(test_class_dir, f)\n",
    "        img = image.load_img(img_path, target_size = (150, 150))\n",
    "        #模型预测\n",
    "        pred = my_network_L1.predict(preprocess_img(img))\n",
    "        test_pred_probs.append(pred)\n",
    "        \n",
    "        pred_label = None\n",
    "        if pred[0] > 0.5:\n",
    "            pred_label = 'dog'\n",
    "        else:\n",
    "            pred_label = 'cat'\n",
    "        test_pred_labels.append(pred_label)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data={'file':files_name, 'true_label':test_true_labels,  'pred_label':test_pred_labels, 'pred_prob':test_pred_probs})\n",
    "\n",
    "\n",
    "        \n",
    "pred_correct_records = df[df['true_label'] == df['pred_label']].shape[0]\n",
    "correct_rate = float(pred_correct_records)/float(1000)\n",
    "correct_rate    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 对照组之三：仅使用L1范数\n",
    "### 3.1 按需建模，设置regularizers.l2(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "#conv2D的filters从32增加到128\n",
    "my_network_L2 = models.Sequential()\n",
    "#32个filter\n",
    "my_network_L2.add(layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (150,150,3)))\n",
    "my_network_L2.add(layers.MaxPooling2D((2,2)))\n",
    "#64个filter\n",
    "my_network_L2.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "my_network_L2.add(layers.MaxPooling2D((2,2)))\n",
    "#128个filter\n",
    "my_network_L2.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n",
    "my_network_L2.add(layers.MaxPooling2D((2,2)))\n",
    "#128个filter\n",
    "my_network_L2.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n",
    "my_network_L2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "my_network_L2.add(layers.Flatten()) #将3D展平为1D\n",
    "#为防止过拟合，使用dropout\n",
    "#my_network_L1.add(layers.Dropout(0.5))\n",
    "my_network_L2.add(layers.Dense(512, kernel_regularizer = regularizers.l2(0.001), activation = 'relu'))\n",
    "my_network_L2.add(layers.Dense(1,activation='sigmoid'))#最后输出二元分类概率\n",
    "\n",
    "\n",
    "from keras import optimizers\n",
    "my_network_L2.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 67s 674ms/step - loss: 1.3403 - acc: 0.5390 - val_loss: 1.1124 - val_acc: 0.5910\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 68s 683ms/step - loss: 0.9948 - acc: 0.5935 - val_loss: 0.8991 - val_acc: 0.6300\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 68s 685ms/step - loss: 0.8481 - acc: 0.6570 - val_loss: 0.8235 - val_acc: 0.6520\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 69s 685ms/step - loss: 0.7665 - acc: 0.7025 - val_loss: 0.7663 - val_acc: 0.6860\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 68s 677ms/step - loss: 0.7153 - acc: 0.7305 - val_loss: 0.8328 - val_acc: 0.6210\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 69s 686ms/step - loss: 0.6714 - acc: 0.7410 - val_loss: 0.7364 - val_acc: 0.6700\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 68s 680ms/step - loss: 0.6367 - acc: 0.7565 - val_loss: 0.6934 - val_acc: 0.7090\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 68s 681ms/step - loss: 0.5983 - acc: 0.7750 - val_loss: 0.6899 - val_acc: 0.7130\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 68s 682ms/step - loss: 0.5799 - acc: 0.7860 - val_loss: 0.6748 - val_acc: 0.7170\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 68s 680ms/step - loss: 0.5483 - acc: 0.8015 - val_loss: 0.6495 - val_acc: 0.7300\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 68s 679ms/step - loss: 0.5210 - acc: 0.8105 - val_loss: 0.6476 - val_acc: 0.7290\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 68s 679ms/step - loss: 0.5001 - acc: 0.8285 - val_loss: 0.6901 - val_acc: 0.7100\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 69s 686ms/step - loss: 0.4740 - acc: 0.8375 - val_loss: 0.6381 - val_acc: 0.7380\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 69s 686ms/step - loss: 0.4551 - acc: 0.8450 - val_loss: 0.6472 - val_acc: 0.7310\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 68s 682ms/step - loss: 0.4277 - acc: 0.8595 - val_loss: 0.6557 - val_acc: 0.7490\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 68s 683ms/step - loss: 0.4097 - acc: 0.8600 - val_loss: 0.6793 - val_acc: 0.7170\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 69s 687ms/step - loss: 0.3884 - acc: 0.8845 - val_loss: 0.6741 - val_acc: 0.7340\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 69s 685ms/step - loss: 0.3699 - acc: 0.8860 - val_loss: 0.7034 - val_acc: 0.7320\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 69s 688ms/step - loss: 0.3509 - acc: 0.8890 - val_loss: 0.6741 - val_acc: 0.7320\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 69s 689ms/step - loss: 0.3352 - acc: 0.9025 - val_loss: 0.6764 - val_acc: 0.7360\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 68s 683ms/step - loss: 0.3066 - acc: 0.9245 - val_loss: 0.7305 - val_acc: 0.7330\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 69s 691ms/step - loss: 0.2980 - acc: 0.9275 - val_loss: 0.8299 - val_acc: 0.7170\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 69s 687ms/step - loss: 0.2764 - acc: 0.9315 - val_loss: 0.7587 - val_acc: 0.7300\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 69s 687ms/step - loss: 0.2622 - acc: 0.9380 - val_loss: 0.7589 - val_acc: 0.7340\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 69s 685ms/step - loss: 0.2439 - acc: 0.9470 - val_loss: 0.7603 - val_acc: 0.7270\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 69s 692ms/step - loss: 0.2373 - acc: 0.9465 - val_loss: 0.7744 - val_acc: 0.7260\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 68s 677ms/step - loss: 0.2161 - acc: 0.9560 - val_loss: 0.8302 - val_acc: 0.7380\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 69s 692ms/step - loss: 0.2021 - acc: 0.9625 - val_loss: 0.8003 - val_acc: 0.7410\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 69s 686ms/step - loss: 0.1874 - acc: 0.9680 - val_loss: 0.9384 - val_acc: 0.7270\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 69s 692ms/step - loss: 0.1793 - acc: 0.9675 - val_loss: 0.9575 - val_acc: 0.7180\n"
     ]
    }
   ],
   "source": [
    "history_L2 = my_network_L2.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs = 30,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 50)\n",
    "\n",
    "my_network_L2.save('D:/2-AI读书学习笔记/0-python深度学习/0-model_repo/cats_and_dogs_small_my_network_with_L2.h5')\n",
    "import pickle\n",
    "with open('D:/2-AI读书学习笔记/0-python深度学习/0-model_repo/ch5_2_network_cnn_L2_trainHistoryDict.txt', 'wb') as file_pi:\n",
    "    pickle.dump(history_L2.history, file_pi)#将训练历史数据保存到指定文件中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 评估L2选项对模型在测试集分类准确率上的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.714"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "\n",
    "classes = ['cats','dogs']\n",
    "files_name = []\n",
    "test_true_labels = []\n",
    "test_pred_labels = []\n",
    "test_pred_probs = []\n",
    "\n",
    "for c in classes:\n",
    "    test_class_dir = 'D:/2-AI读书学习笔记/99-dataset-lib/cat_dog/small_dataset_cat_dog/test/{}'.format(c)\n",
    "    for f in os.listdir(test_class_dir):\n",
    "        \n",
    "        files_name.append(f)\n",
    "        test_true_labels.append(f[0:3])\n",
    "        \n",
    "        img_path = os.path.join(test_class_dir, f)\n",
    "        img = image.load_img(img_path, target_size = (150, 150))\n",
    "        #模型预测\n",
    "        pred = my_network_L2.predict(preprocess_img(img))\n",
    "        test_pred_probs.append(pred)\n",
    "        \n",
    "        pred_label = None\n",
    "        if pred[0] > 0.5:\n",
    "            pred_label = 'dog'\n",
    "        else:\n",
    "            pred_label = 'cat'\n",
    "        test_pred_labels.append(pred_label)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data={'file':files_name, 'true_label':test_true_labels,  'pred_label':test_pred_labels, 'pred_prob':test_pred_probs})\n",
    "\n",
    "\n",
    "        \n",
    "pred_correct_records = df[df['true_label'] == df['pred_label']].shape[0]\n",
    "correct_rate = float(pred_correct_records)/float(1000)\n",
    "correct_rate   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 对照组之四：仅缩减网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 按需建模，卷积层由4层减少为3层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "#conv2D的filters从32增加到128\n",
    "my_network_simple = models.Sequential()\n",
    "#32个filter\n",
    "my_network_simple.add(layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (150,150,3)))\n",
    "my_network_simple.add(layers.MaxPooling2D((2,2)))\n",
    "#64个filter\n",
    "my_network_simple.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "my_network_simple.add(layers.MaxPooling2D((2,2)))\n",
    "#128个filter\n",
    "my_network_simple.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n",
    "my_network_simple.add(layers.MaxPooling2D((2,2)))\n",
    "# #128个filter\n",
    "# my_network_L2.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n",
    "# my_network_L2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "my_network_simple.add(layers.Flatten()) #将3D展平为1D\n",
    "#为防止过拟合，使用dropout\n",
    "#my_network_L1.add(layers.Dropout(0.5))\n",
    "my_network_simple.add(layers.Dense(512,activation = 'relu'))\n",
    "my_network_simple.add(layers.Dense(1,activation='sigmoid'))#最后输出二元分类概率\n",
    "\n",
    "\n",
    "from keras import optimizers\n",
    "my_network_simple.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 77s 770ms/step - loss: 0.6835 - acc: 0.5740 - val_loss: 0.7233 - val_acc: 0.5540\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 77s 766ms/step - loss: 0.6044 - acc: 0.6730 - val_loss: 0.6188 - val_acc: 0.6490\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 77s 767ms/step - loss: 0.5344 - acc: 0.7335 - val_loss: 0.5982 - val_acc: 0.6780\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.4931 - acc: 0.7650 - val_loss: 0.7499 - val_acc: 0.5970\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 76s 764ms/step - loss: 0.4521 - acc: 0.7830 - val_loss: 0.6823 - val_acc: 0.6570\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 78s 784ms/step - loss: 0.4078 - acc: 0.8175 - val_loss: 0.6023 - val_acc: 0.6890\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.3681 - acc: 0.8420 - val_loss: 0.6210 - val_acc: 0.6820\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.3325 - acc: 0.8560 - val_loss: 0.6517 - val_acc: 0.6880\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 77s 768ms/step - loss: 0.2920 - acc: 0.8850 - val_loss: 0.6090 - val_acc: 0.7100\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 77s 768ms/step - loss: 0.2602 - acc: 0.8985 - val_loss: 0.6348 - val_acc: 0.6970\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 76s 762ms/step - loss: 0.2273 - acc: 0.9160 - val_loss: 0.6766 - val_acc: 0.7130\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 77s 767ms/step - loss: 0.1931 - acc: 0.9345 - val_loss: 0.6945 - val_acc: 0.6960\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.1701 - acc: 0.9410 - val_loss: 0.8233 - val_acc: 0.6930\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 76s 760ms/step - loss: 0.1482 - acc: 0.9525 - val_loss: 0.6776 - val_acc: 0.7370\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 77s 769ms/step - loss: 0.1202 - acc: 0.9655 - val_loss: 0.8008 - val_acc: 0.7180\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.0987 - acc: 0.9745 - val_loss: 0.8030 - val_acc: 0.7230\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 78s 777ms/step - loss: 0.0786 - acc: 0.9780 - val_loss: 0.8246 - val_acc: 0.7180\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.0732 - acc: 0.9840 - val_loss: 1.1829 - val_acc: 0.6760\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 0.0563 - acc: 0.9890 - val_loss: 1.0127 - val_acc: 0.6870\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.0459 - acc: 0.9925 - val_loss: 0.9497 - val_acc: 0.7110\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 77s 773ms/step - loss: 0.0370 - acc: 0.9930 - val_loss: 1.0337 - val_acc: 0.7110\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 77s 770ms/step - loss: 0.0295 - acc: 0.9945 - val_loss: 1.0229 - val_acc: 0.7260\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.0232 - acc: 0.9960 - val_loss: 1.1149 - val_acc: 0.7190\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 77s 770ms/step - loss: 0.0217 - acc: 0.9950 - val_loss: 1.1463 - val_acc: 0.7210\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.0158 - acc: 0.9965 - val_loss: 1.2968 - val_acc: 0.7130\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 77s 770ms/step - loss: 0.0165 - acc: 0.9950 - val_loss: 1.2820 - val_acc: 0.7200\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 77s 769ms/step - loss: 0.0138 - acc: 0.9965 - val_loss: 1.3271 - val_acc: 0.7140\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 77s 772ms/step - loss: 0.0121 - acc: 0.9970 - val_loss: 1.4007 - val_acc: 0.7100\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.0184 - acc: 0.9945 - val_loss: 1.3231 - val_acc: 0.7350\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 77s 767ms/step - loss: 0.0100 - acc: 0.9975 - val_loss: 1.4024 - val_acc: 0.7250\n"
     ]
    }
   ],
   "source": [
    "history_simple = my_network_simple.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs = 30,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 50)\n",
    "\n",
    "my_network_simple.save('D:/2-AI读书学习笔记/0-python深度学习/0-model_repo/cats_and_dogs_small_my_network_with_simple.h5')\n",
    "\n",
    "import pickle\n",
    "with open('D:/2-AI读书学习笔记/0-python深度学习/0-model_repo/ch5_2_network_cnn_simple_trainHistoryDict.txt', 'wb') as file_pi:\n",
    "    pickle.dump(history_simple.history, file_pi)#将训练历史数据保存到指定文件中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 评估缩减CNN网络规模对模型在测试集分类准确率上的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.711"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "\n",
    "classes = ['cats','dogs']\n",
    "files_name = []\n",
    "test_true_labels = []\n",
    "test_pred_labels = []\n",
    "test_pred_probs = []\n",
    "\n",
    "for c in classes:\n",
    "    test_class_dir = 'D:/2-AI读书学习笔记/99-dataset-lib/cat_dog/small_dataset_cat_dog/test/{}'.format(c)\n",
    "    for f in os.listdir(test_class_dir):\n",
    "        \n",
    "        files_name.append(f)\n",
    "        test_true_labels.append(f[0:3])\n",
    "        \n",
    "        img_path = os.path.join(test_class_dir, f)\n",
    "        img = image.load_img(img_path, target_size = (150, 150))\n",
    "        #模型预测\n",
    "        pred = my_network_simple.predict(preprocess_img(img))\n",
    "        test_pred_probs.append(pred)\n",
    "        \n",
    "        pred_label = None\n",
    "        if pred[0] > 0.5:\n",
    "            pred_label = 'dog'\n",
    "        else:\n",
    "            pred_label = 'cat'\n",
    "        test_pred_labels.append(pred_label)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data={'file':files_name, 'true_label':test_true_labels,  'pred_label':test_pred_labels, 'pred_prob':test_pred_probs})\n",
    "\n",
    "\n",
    "        \n",
    "pred_correct_records = df[df['true_label'] == df['pred_label']].shape[0]\n",
    "correct_rate = float(pred_correct_records)/float(1000)\n",
    "correct_rate   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 对照组之五：同时使用dropout与数据增强技术"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 按需建模，droupout设置为0.5；同时设置带数据增强的图片生成器实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen_with_da = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest')\n",
    "\n",
    "train_generator_with_da = train_datagen_with_da.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (150,150),\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "#conv2D的filters从32增加到128\n",
    "my_network_droupout_da = models.Sequential()\n",
    "#32个filter\n",
    "my_network_droupout_da.add(layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (150,150,3)))\n",
    "my_network_droupout_da.add(layers.MaxPooling2D((2,2)))\n",
    "#64个filter\n",
    "my_network_droupout_da.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "my_network_droupout_da.add(layers.MaxPooling2D((2,2)))\n",
    "#128个filter\n",
    "my_network_droupout_da.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n",
    "my_network_droupout_da.add(layers.MaxPooling2D((2,2)))\n",
    "# #128个filter\n",
    "# my_network_L2.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n",
    "# my_network_L2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "my_network_droupout_da.add(layers.Flatten()) #将3D展平为1D\n",
    "#为防止过拟合，使用dropout\n",
    "my_network_droupout_da.add(layers.Dropout(0.5))\n",
    "my_network_droupout_da.add(layers.Dense(512, activation = 'relu'))\n",
    "my_network_droupout_da.add(layers.Dense(1,activation='sigmoid'))#最后输出二元分类概率\n",
    "\n",
    "\n",
    "from keras import optimizers\n",
    "my_network_droupout_da.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 76s 763ms/step - loss: 0.7043 - acc: 0.5330 - val_loss: 0.6821 - val_acc: 0.5870\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.6837 - acc: 0.5495 - val_loss: 0.6640 - val_acc: 0.5860\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 76s 758ms/step - loss: 0.6699 - acc: 0.5870 - val_loss: 0.6416 - val_acc: 0.6360\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 77s 769ms/step - loss: 0.6579 - acc: 0.6180 - val_loss: 0.6650 - val_acc: 0.5730\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 77s 769ms/step - loss: 0.6336 - acc: 0.6400 - val_loss: 0.6001 - val_acc: 0.6810\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 77s 766ms/step - loss: 0.6275 - acc: 0.6450 - val_loss: 0.6541 - val_acc: 0.5950\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 75s 749ms/step - loss: 0.6111 - acc: 0.6620 - val_loss: 0.6466 - val_acc: 0.6160\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 74s 737ms/step - loss: 0.5945 - acc: 0.6760 - val_loss: 0.5698 - val_acc: 0.7110\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 76s 760ms/step - loss: 0.5919 - acc: 0.6835 - val_loss: 0.6244 - val_acc: 0.6330\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 75s 748ms/step - loss: 0.5980 - acc: 0.6700 - val_loss: 0.5610 - val_acc: 0.7030\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 76s 757ms/step - loss: 0.5862 - acc: 0.6835 - val_loss: 0.5489 - val_acc: 0.7180\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 76s 756ms/step - loss: 0.5743 - acc: 0.6995 - val_loss: 0.5655 - val_acc: 0.7160\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 76s 765ms/step - loss: 0.5705 - acc: 0.7010 - val_loss: 0.5252 - val_acc: 0.7390\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 76s 757ms/step - loss: 0.5762 - acc: 0.6980 - val_loss: 0.5215 - val_acc: 0.7300\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 75s 745ms/step - loss: 0.5575 - acc: 0.7145 - val_loss: 0.5261 - val_acc: 0.7310\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 76s 757ms/step - loss: 0.5588 - acc: 0.7085 - val_loss: 0.7245 - val_acc: 0.6290\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 82s 818ms/step - loss: 0.5584 - acc: 0.7125 - val_loss: 0.5303 - val_acc: 0.7130\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 83s 832ms/step - loss: 0.5667 - acc: 0.7120 - val_loss: 0.5246 - val_acc: 0.7330\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 76s 758ms/step - loss: 0.5514 - acc: 0.7065 - val_loss: 0.5132 - val_acc: 0.7350\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 78s 780ms/step - loss: 0.5421 - acc: 0.7280 - val_loss: 0.5040 - val_acc: 0.7430\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 74s 739ms/step - loss: 0.5416 - acc: 0.7250 - val_loss: 0.4992 - val_acc: 0.7480\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 73s 732ms/step - loss: 0.5425 - acc: 0.7290 - val_loss: 0.5760 - val_acc: 0.6960\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 74s 738ms/step - loss: 0.5268 - acc: 0.7320 - val_loss: 0.5056 - val_acc: 0.7460\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 76s 763ms/step - loss: 0.5335 - acc: 0.7280 - val_loss: 0.4970 - val_acc: 0.7460\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 77s 766ms/step - loss: 0.5197 - acc: 0.7350 - val_loss: 0.4875 - val_acc: 0.7540\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 76s 760ms/step - loss: 0.5284 - acc: 0.7285 - val_loss: 0.4827 - val_acc: 0.7620\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 76s 757ms/step - loss: 0.5337 - acc: 0.7330 - val_loss: 0.5073 - val_acc: 0.7370\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 74s 741ms/step - loss: 0.5229 - acc: 0.7340 - val_loss: 0.5227 - val_acc: 0.7460\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 73s 734ms/step - loss: 0.5176 - acc: 0.7365 - val_loss: 0.4655 - val_acc: 0.7700\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 75s 754ms/step - loss: 0.5207 - acc: 0.7345 - val_loss: 0.4854 - val_acc: 0.7610\n"
     ]
    }
   ],
   "source": [
    "history_droupout_da = my_network_droupout_da.fit_generator(\n",
    "    train_generator_with_da,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs = 30,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 50)\n",
    "\n",
    "my_network_droupout_da.save('D:/2-AI读书学习笔记/0-python深度学习/0-model_repo/cats_and_dogs_small_my_network_with_dropout_da.h5')\n",
    "\n",
    "import pickle\n",
    "with open('D:/2-AI读书学习笔记/0-python深度学习/0-model_repo/ch5_2_network_cnn_droupout_da_trainHistoryDict.txt', 'wb') as file_pi:\n",
    "    pickle.dump(history_droupout_da.history, file_pi)#将训练历史数据保存到指定文件中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 评估dropout与数据增强两个选项复合使用时，对模型在测试集的分类准确率的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.749"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "\n",
    "classes = ['cats','dogs']\n",
    "files_name = []\n",
    "test_true_labels = []\n",
    "test_pred_labels = []\n",
    "test_pred_probs = []\n",
    "\n",
    "for c in classes:\n",
    "    test_class_dir = 'D:/2-AI读书学习笔记/99-dataset-lib/cat_dog/small_dataset_cat_dog/test/{}'.format(c)\n",
    "    for f in os.listdir(test_class_dir):\n",
    "        \n",
    "        files_name.append(f)\n",
    "        test_true_labels.append(f[0:3])\n",
    "        \n",
    "        img_path = os.path.join(test_class_dir, f)\n",
    "        img = image.load_img(img_path, target_size = (150, 150))\n",
    "        pred = my_network_droupout_da.predict(preprocess_img(img))\n",
    "        test_pred_probs.append(pred)\n",
    "        \n",
    "        pred_label = None\n",
    "        if pred[0] > 0.5:\n",
    "            pred_label = 'dog'\n",
    "        else:\n",
    "            pred_label = 'cat'\n",
    "        test_pred_labels.append(pred_label) \n",
    "        \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data={'file':files_name, 'true_label':test_true_labels,  'pred_label':test_pred_labels, 'pred_prob':test_pred_probs})\n",
    "\n",
    "\n",
    "        \n",
    "pred_correct_records = df[df['true_label'] == df['pred_label']].shape[0]\n",
    "correct_rate = float(pred_correct_records)/float(1000)\n",
    "correct_rate "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
